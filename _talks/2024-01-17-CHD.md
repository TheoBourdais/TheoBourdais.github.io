---
title: "Talk on Computational Hypergraph Discovery"
collection: talks
type: "Talk"
permalink: /talks/2024-01-17-CHD
venue: "One World Seminar Series on the Mathematics of Machine Learning"
date: 2024-01-17
location: "Online"
---

My talk on Computational Hypergraph discovery! I have given versions of this talk at:
- the [One World Seminar Series on the Mathematics of Machine Learning](https://www.oneworldml.org/home) on January 17th, 2024.
    - [Slides](/files/CHD_one_world_seminar.pdf)
    - [Video](https://youtu.be/XIz2Va_wXrc)
- the [Differential Equations for Data Science 2024 (DEDS2024)](https://scheme.hn/deds2024/) conference on February 19th, 2024.
    - [Video](https://scheme.hn/deds2024/videos/bourdais.mp4)
- the [SIAM UQ 2024](https://www.siam.org/conferences/cm/conference/uq24) conference in Trieste on March 29th, 2024.
- the [Digital twins for inverse problems in Earth science](https://conferences.cirm-math.fr/3264.html) workshop in Marseille on July 23rd, 2024. 
- [SIAM Mathematics of Data Science (SIAM MDS)](https://www.siam.org/conferences-events/siam-conferences/mds24/) on October 24th, 2024
- [DTE AICOMAS](https://dte_aicomas_2025.iacm.info/) in Paris on February 18th, 2025.


Abstract
======
Most scientific challenges can be framed into one of the following three levels of complexity of function approximation. Type 1: Approximate an unknown function given input/output data. Type 2: Consider a collection of variables and functions, some of which are unknown, indexed by the nodes and hyperedges of a hypergraph (a generalized graph where edges can connect more than two vertices). Given partial observations of the variables of the hypergraph (satisfying the functional dependencies imposed by its structure), approximate all the unobserved variables and unknown functions. Type 3: Expanding on Type 2, if the hypergraph structure itself is unknown, use partial observations of the variables of the hypergraph to discover its structure and approximate its unknown functions. While most Computational Science and Engineering and Scientific Machine Learning challenges can be framed as Type 1 and Type 2 problems, many scientific problems can only be categorized as Type 3. Despite their prevalence, these Type 3 challenges have been largely overlooked due to their inherent complexity. Although Gaussian Process (GP) methods are sometimes perceived as well-founded but old technology limited to Type 1 curve fitting, their scope has recently been expanded to Type 2 problems. 

We introduce an interpretable GP framework for Type 3 problems, targeting the data-driven discovery and completion of computational hypergraphs. Our approach is based on a kernel generalization of (1) Row Echelon Form reduction from linear systems to nonlinear ones and (2) variance-based analysis. Here, variables are linked via GPs, and those contributing to the highest data variance unveil the hypergraphâ€™s structure. We illustrate the scope and efficiency of the proposed approach with applications to network discovery (gene pathways, chemical, and mechanical), and raw data analysis.
